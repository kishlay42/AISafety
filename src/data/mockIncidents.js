export const mockIncidents = [
  {
    id: 1,
    title: "LLM Hallucination in Critical Info",
    description: "LLM provided incorrect safety procedure information during emergency response simulation, highlighting potential risks in critical decision-making scenarios. The model generated plausible but dangerously incorrect emergency protocols that could have led to severe consequences if implemented.",
    severity: "High",
    reported_at: "2025-04-01T20:00:00Z"
  },
  {
    id: 2,
    title: "Minor Data Leak via Chatbot",
    description: "Chatbot inadvertently exposed non-sensitive user metadata during conversation, requiring privacy protocol updates. The incident affected a small number of users and involved non-critical information.",
    severity: "Low",
    reported_at: "2025-03-20T02:45:00Z"
  },
  {
    id: 3,
    title: "AI Model Bias in Healthcare Recommendations",
    description: "Systematic bias detected in healthcare recommendation system, showing disparities in treatment suggestions across different demographic groups. Initial analysis indicates potential training data imbalance.",
    severity: "High",
    reported_at: "2025-03-15T14:30:00Z"
  },
  {
    id: 4,
    title: "Automated Content Moderation False Positives",
    description: "Content moderation AI system showing increased false positive rate for policy violations, affecting legitimate content across multiple languages and cultural contexts.",
    severity: "Medium",
    reported_at: "2025-03-10T09:15:00Z"
  },
  {
    id: 5,
    title: "AI System Resource Overconsumption",
    description: "Large language model deployment caused unexpected server resource spikes, leading to temporary service degradation for critical applications.",
    severity: "Medium",
    reported_at: "2025-03-05T16:20:00Z"
  },
  {
    id: 6,
    title: "Adversarial Attack on Vision System",
    description: "Detected sophisticated adversarial attack attempting to manipulate computer vision system in autonomous vehicle testing environment. No accidents occurred, but highlighted security vulnerability.",
    severity: "High",
    reported_at: "2025-02-28T11:00:00Z"
  },
  {
    id: 7,
    title: "Model Performance Degradation",
    description: "Gradual decline in model performance observed over time due to concept drift, affecting recommendation accuracy across multiple domains.",
    severity: "Medium",
    reported_at: "2025-02-20T13:45:00Z"
  },
  {
    id: 8,
    title: "Privacy Preservation Failure in Federated Learning",
    description: "Potential privacy leakage discovered in federated learning system, possibly exposing partial training data patterns. No direct data exposure confirmed.",
    severity: "High",
    reported_at: "2025-02-15T08:30:00Z"
  },
  {
    id: 9,
    title: "Language Model Inappropriate Response",
    description: "Customer-facing chatbot generated inappropriate responses in specific edge cases, potentially affecting brand reputation. No harmful content, but professional standards not met.",
    severity: "Low",
    reported_at: "2025-02-10T15:10:00Z"
  },
  {
    id: 10,
    title: "AI Decision Explanation Inconsistency",
    description: "Inconsistencies detected between AI system decisions and their explanations in financial service recommendations, raising transparency concerns.",
    severity: "Medium",
    reported_at: "2025-02-05T10:20:00Z"
  },
  {
    id: 11,
    title: "Training Data Quality Issue",
    description: "Discovered contaminated training data affecting model behavior in production. Impact limited to non-critical features.",
    severity: "Low",
    reported_at: "2025-01-30T14:15:00Z"
  },
  {
    id: 12,
    title: "Model Output Manipulation Vulnerability",
    description: "Security audit revealed potential vulnerability allowing manipulation of model outputs through carefully crafted inputs. No exploitation detected in production.",
    severity: "High",
    reported_at: "2025-01-25T09:45:00Z"
  }
]; 